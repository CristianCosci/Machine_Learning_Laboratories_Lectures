{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvGMkUUbMUw"
      },
      "source": [
        "### Introduction to CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGXZ7FfsbMUy"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms12IDn1bMUz"
      },
      "source": [
        "A couple utility functions to plot grayscale and RGB images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3z_pW-B5bMUz"
      },
      "outputs": [],
      "source": [
        "def plot_image(image):\n",
        "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "def plot_color_image(image):\n",
        "    plt.imshow(image, interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBs8fAzPbMU0"
      },
      "source": [
        "# What is a Convolution?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "GJaQWcWzbMU1",
        "outputId": "fccbd274-0687-4ca0-d705-28077b90ef92"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_sample_image\n",
        "\n",
        "# Load sample images\n",
        "china = load_sample_image(\"china.jpg\") / 255\n",
        "flower = load_sample_image(\"flower.jpg\") / 255\n",
        "images = np.array([china, flower])\n",
        "batch_size, height, width, channels = ?\n",
        "\n",
        "plt.imshow(china) # plot 1st image\n",
        "plt.axis(\"off\") # Not shown in the book\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create 2 filters\n",
        "filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)\n",
        "filters[?] = ?  # vertical line\n",
        "filters[?] = ?  # horizontal line\n",
        "\n",
        "outputs = tf.nn.conv2d(images, filters, strides=1, padding=\"SAME\")\n",
        "\n",
        "plt.imshow(outputs[0, :, :, 1], cmap=\"gray\") # plot 1st image's 2nd feature map\n",
        "plt.axis(\"off\") # Not shown in the book\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "0RFMd4hVbMU1",
        "outputId": "d939be1b-2824-40b5-de78-007e4ad95009"
      },
      "outputs": [],
      "source": [
        "for image_index in (0, 1):\n",
        "    for feature_map_index in (0, 1):\n",
        "        plt.subplot(2, 2, image_index * 2 + feature_map_index + 1)\n",
        "        plot_image(outputs[image_index, :, :, feature_map_index])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdEY_LfIbMU2"
      },
      "outputs": [],
      "source": [
        "def crop(images):\n",
        "    return images[?]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "lPoWFzOubMU2",
        "outputId": "a3d2e9f9-20b9-40d6-8926-73367103a7d2"
      },
      "outputs": [],
      "source": [
        "plot_image(crop(images[0, :, :, 0]))\n",
        "plt.show()\n",
        "\n",
        "for feature_map_index, filename in enumerate([\"china_vertical\", \"china_horizontal\"]):\n",
        "    plot_image(crop(outputs[0, :, :, feature_map_index]))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "AU34Ai1fbMU3",
        "outputId": "aba06c2c-fce1-4f2d-e386-1b5cb2cde312"
      },
      "outputs": [],
      "source": [
        "plot_image(filters[?])\n",
        "plt.show()\n",
        "plot_image(filters[?])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnHBLlprbMU3"
      },
      "source": [
        "## Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxpTg7rLbMU3"
      },
      "source": [
        "Let's create a 2D convolutional layer, using `keras.layers.Conv2D()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVcwa3wVbMU4"
      },
      "outputs": [],
      "source": [
        "np.random.seed(40)\n",
        "tf.random.set_seed(40)\n",
        "\n",
        "conv = keras.layers.Conv2D(filters=2, kernel_size=7, strides=1,\n",
        "                           padding=\"SAME\", activation=\"relu\", input_shape=outputs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfP2ipPabMU4"
      },
      "source": [
        "Let's call this layer, passing it the two test images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC_yU8mrbMU4",
        "outputId": "da360f1e-ef63-4487-c0b6-b339c7af381c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([2, 427, 640, 2])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_outputs = conv(images)\n",
        "conv_outputs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd4cFyl2bMU4"
      },
      "source": [
        "The output is a 4D tensor. \n",
        "\n",
        "The dimensions are: `batch size, height, width, channels`. \n",
        "\n",
        "The first dimension (`batch size`) is 2 since there are 2 input images.\n",
        "\n",
        "The next two dimensions are the `height` and `width` of the output feature maps: since `padding=\"SAME\"` and `strides=1`, the output feature maps have the same height and width as the input images (in this case, 427Ã—640).\n",
        "\n",
        "Lastly, this convolutional layer has 2 filters, so the last dimension is 2: there are 2 output feature maps per input image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFsFp_ydbMU4"
      },
      "source": [
        "Since the filters are initialized randomly, they'll initially detect random patterns. Let's take a look at the 2 output features maps for each image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "24qm2yJkbMU5",
        "outputId": "5258a6d3-373e-4ca7-d1f1-1122142d40ea"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for image_index in (0, 1):\n",
        "    for feature_map_index in (0, 1):\n",
        "        plt.subplot(2, 2, image_index * 2 + feature_map_index + 1)\n",
        "        plot_image(crop(conv_outputs[image_index, :, :, feature_map_index]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbQQVbWTbMU5"
      },
      "source": [
        "Although the filters were initialized **randomly**, the second filter happens to act like an **edge detector**. \n",
        "\n",
        "**Randomly initialized filters often act this way, which is quite fortunate since detecting edges is quite useful in image processing.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us4KhHd9bMU5"
      },
      "source": [
        "If we want, we can set the filters to be the ones we manually defined earlier, and set the biases to zeros (in real life we will almost never need to set filters or biases manually, as **the convolutional layer will just learn the appropriate filters and biases during training**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT6cm-3xbMU6"
      },
      "outputs": [],
      "source": [
        "conv.set_weights([filters, np.zeros(2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBaqeD97bMU6"
      },
      "source": [
        "Now let's call this layer again on the same two images, and let's check that the output feature maps do highlight vertical lines and horizontal lines, respectively (as earlier):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk6QbgBVbMU6",
        "outputId": "5c92f650-3376-43fe-a982-9145bbb47f3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([2, 427, 640, 2])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_outputs = conv(images)\n",
        "conv_outputs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "2kyRj1U3bMU6",
        "outputId": "044bbfcf-faf4-4f06-8bb5-8fef82c0d031"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for image_index in (0, 1):\n",
        "    for feature_map_index in (0, 1):\n",
        "        plt.subplot(2, 2, image_index * 2 + feature_map_index + 1)\n",
        "        plot_image(crop(conv_outputs[image_index, :, :, feature_map_index]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnjhcXCgbMU8"
      },
      "source": [
        "# Pooling layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF71cud9bMU8"
      },
      "source": [
        "## Max pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcXDwhiUbMU9"
      },
      "outputs": [],
      "source": [
        "max_pool = keras.layers.MaxPool2D(pool_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AP4rW1GbMU9"
      },
      "outputs": [],
      "source": [
        "cropped_images = np.array([crop(image) for image in images], dtype=np.float32)\n",
        "output = max_pool(cropped_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "NWeL9pubbMU9",
        "outputId": "faed0dfe-4409-456c-9ebe-e9b55a7996bf"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[2, 1])\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(cropped_images[0])  # plot the 1st image\n",
        "ax1.axis(\"off\")\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Output\", fontsize=14)\n",
        "ax2.imshow(output[0])  # plot the output for the 1st image\n",
        "ax2.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2TrcyfubMU_"
      },
      "source": [
        "## Average pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSBwt_t3bMU_"
      },
      "outputs": [],
      "source": [
        "avg_pool = keras.layers.AvgPool2D(pool_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqqfxycVbMU_"
      },
      "outputs": [],
      "source": [
        "output_avg = avg_pool(cropped_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "tbbgv8nxbMVA",
        "outputId": "683ce97d-4804-47dd-c318-982819646996"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(12, 8))\n",
        "gs = mpl.gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[2, 1])\n",
        "\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "ax1.set_title(\"Input\", fontsize=14)\n",
        "ax1.imshow(cropped_images[0])  # plot the 1st image\n",
        "ax1.axis(\"off\")\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "ax2.set_title(\"Output\", fontsize=14)\n",
        "ax2.imshow(output_avg[0])  # plot the output for the 1st image\n",
        "ax2.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
