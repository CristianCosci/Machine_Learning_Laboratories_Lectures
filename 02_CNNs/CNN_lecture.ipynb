{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg-L3oUTlaHI"
      },
      "source": [
        "# Using a CNN to predict images from CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Y-2fDwlx1p"
      },
      "source": [
        "In this lecture we are going to learn about CNN (Convolutional Neural Networks).\n",
        "We will learn how to build and how to use them to make predictions.\n",
        "\n",
        "The dataset of today's classification task is: CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C--TtAiXnIgI"
      },
      "source": [
        "### Dataset loading and some data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJJPqhTAkQZa",
        "outputId": "84ed7e23-2c64-4a45-8fa2-0b1f837b41bc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loading CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "\n",
        "# print dataset shape\n",
        "print(train_images.shape)\n",
        "# and the shape of an image\n",
        "print(train_images[0].shape)\n",
        "\n",
        "# print the range of the values\n",
        "\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "\n",
        "\n",
        "print(\"shape of train_labels:\", train_labels.shape)\n",
        "print(\"object labels are: \", np.unique(train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "MZNooFcqXMnQ",
        "outputId": "4920ad46-754b-401c-b796-5bec9fd66728"
      },
      "outputs": [],
      "source": [
        "# Show the first 25 images in the dataset (in a grid 5x5) with the corresponding labels\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',     # We add the dataset labels just to understand better the output.\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']             # They are provided in the dataset documentation\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(train_images[i])\n",
        "    plt.title(class_names[train_labels[i][0]], fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haIBLBbDnNqh"
      },
      "source": [
        "## Building the CNN\n",
        "\n",
        "We are going to create a CNN model having these hidden layers:\n",
        "1. `layer1`: conv2D having 32 filters of size 3x3, stride=1, ReLu activation\n",
        "2. `layer2`: maxPool with filter size 2x2 and stride=1\n",
        "3. `layer3`: conv2D having 64 filters of size 3x3, stride=1, ReLu activation\n",
        "4. `layer4`: maxPool with filter size 2x2 and stride=1\n",
        "5. `layer5`: conv2D having 64 filters of size 3x3, stride=1, ReLu activation,\n",
        "6. `layer6`: MLP with 64 nodes\n",
        "\n",
        "- **Keras sequential** documentation: https://keras.io/guides/sequential_model/\n",
        "- **Keras documentation for Conv2D** class: https://keras.io/api/layers/convolution_layers/convolution2d/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kmBHPdokdK_",
        "outputId": "aa1a9507-a4ac-4dd8-a7a0-8a5a38752d17"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# CNN model definition\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp-f3SU2nxhK"
      },
      "source": [
        "#### Visualize and plot the model architeture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPy-4DnoMULn",
        "outputId": "140774b4-60b2-4e6e-841f-fe185f57c8eb"
      },
      "outputs": [],
      "source": [
        "!pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "LvdUgQOYMULo",
        "outputId": "45ee0042-5d15-482d-9148-895c3fc7ee6d"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "\n",
        "visualkeras.layered_view(model).show() # display using your system viewer\n",
        "visualkeras.layered_view(model, to_file='output.png') # write to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "id": "VAqgf6m1MULo",
        "outputId": "8353e625-4f58-46f5-8125-04a200748b23"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKBUiq04MULp"
      },
      "source": [
        "### CNN Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cit5H67RkmA-",
        "outputId": "355fba58-8b7d-42ac-9c98-d22f41b47163"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "?\n",
        "\n",
        "# Model training\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MkZY9xHoBWL"
      },
      "source": [
        "### CNN evaluation\n",
        "\n",
        "- All the training data have been stored in a **History** object.\n",
        "- Its `History.history` attribute is a record of training loss values and metrics values at successive epochs, as well as validation loss values and validation metrics values.\n",
        "- If you don't remember how history is made you can run\n",
        "    ```python\n",
        "    type(history.history)\n",
        "    ```\n",
        "- Moreover, since it is a dictionary (a structure key:value) you can list the metrics stored in history (the keys) using\n",
        "    ```python\n",
        "    history.history.keys()\n",
        "    ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMLqPyf_odUu"
      },
      "source": [
        "**Model evaluation**\n",
        "\n",
        "In order to evaluate our model we want to:\n",
        "- plot accuracy curve on training and validation sets\n",
        "- test the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "BPhCeIHMMULq",
        "outputId": "fb8ea6a4-2353-4b45-91e4-a54aaafe1d90"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Degine a subplot grid 1x2\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "# Plot for accuracy and val_accuracy\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch', fontsize=13)\n",
        "plt.ylabel('Accuracy', fontsize=13)\n",
        "plt.ylim([0.0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "# Plot for loss and val_loss\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch', fontsize=13)\n",
        "plt.ylabel('Loss', fontsize=13)\n",
        "plt.ylim([0.0, 2])\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pYmIEmflOv6",
        "outputId": "a751a6fb-68f5-4d8a-fc05-3df36f61d140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 7s 21ms/step - loss: 0.8168 - accuracy: 0.7283\n",
            "Loss on test set: 0.8167517185211182\n",
            "Accuracy on test set: 0.7282999753952026\n"
          ]
        }
      ],
      "source": [
        "# Model evaluation on test data\n",
        "test_loss, test_accuracy = ?\n",
        "\n",
        "print(f'Loss on test set: {test_loss}')\n",
        "print(f'Accuracy on test set: {test_accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shIcgv4qo-Ad"
      },
      "source": [
        "### Confusion matrix\n",
        "\n",
        "- A confusion matrix is a performance measurement tool used in classification tasks, to evaluate the performance of a classification model. \n",
        "- It is a square matrix where each row represents the instances in a predicted class, and each column represents the instances in an actual class (or vice versa). \n",
        "- The diagonal elements of the matrix represent the number of correct predictions for each class, while the off-diagonal elements represent incorrect predictions.\n",
        "\n",
        "By analyzing the confusion matrix, we can gain insights into the model's performance, such as:\n",
        "- `Accuracy`: The overall accuracy of the model, calculated as the ratio of the sum of correct predictions to the total number of predictions.\n",
        "- `Precision`: The ratio of true positive predictions to the total number of positive predictions, indicating the model's ability to correctly identify positive cases.\n",
        "- `Recall`: The ratio of true positive predictions to the total number of actual positive cases, indicating the model's ability to capture all positive cases.\n",
        "- `F1 Score`: The harmonic mean of precision and recall, providing a balance between the two metrics.\n",
        "\n",
        "Overall, the confusion matrix provides a comprehensive overview of the model's performance across different classes, enabling us to identify areas for improvement and fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "uHpu4LeXg90X",
        "outputId": "dd4478cc-1139-4555-8f58-8feb3b788d6d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn    # https://seaborn.pydata.org/\n",
        "import pandas  as pd\n",
        "\n",
        "y_pred = model.predict(test_images)\n",
        "# print(y_pred.argmax(axis=1))\n",
        "# print(y_pred)\n",
        "matrix = confusion_matrix(test_labels, y_pred.argmax(axis=1)) \n",
        "# print(matrix)\n",
        "\n",
        "df_cm = pd.DataFrame(matrix, range(10),range(10))\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4) #for label size\n",
        "sn.heatmap(df_cm, cmap=\"BuPu\",annot=True,annot_kws={\"size\": 10})# font size\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUm1EgnPpSli"
      },
      "source": [
        "### **Visualize the feature maps**\n",
        "Feature maps are the **representations of features extracted from the input image at each level of the CNN**.\n",
        "\n",
        "To visualize the latent features computed by a convolutional layer for a given image, you have to extract the output values of that layer. \n",
        "\n",
        "To do this:\n",
        "- you need to create a new model with the same input as the original model and the layer you want to analyze as the output layer.\n",
        "- once you have this new model, you can call it on the image you want to visualize, and it will output the feature maps for that specific layer.\n",
        "\n",
        "This can help you understand what features the model is detecting in the image and how it is processing the input data.\n",
        "\n",
        "To access the layers, you can use  `model.layers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpOCqCAvhCXS",
        "outputId": "f5060907-75de-48ae-c0d6-e60be17b5ea6"
      },
      "outputs": [],
      "source": [
        "# Print the name and shape of the conv layers\n",
        "\n",
        "print(type(model.layers))\n",
        "print(model.layers[0])\n",
        "\n",
        "?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiGrJkoYMULr"
      },
      "source": [
        "1. Show the feature maps extracted by the first conv layer\n",
        "2. Build a new model to output right after the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p7MVtOHhE9K",
        "outputId": "60682751-69fd-44ce-ff1d-13d83fcf3edf"
      },
      "outputs": [],
      "source": [
        "# You can get the model by its name, but consider that the names assigned change if you re-run the code\n",
        "# It's better to select the layer using the list index\n",
        "from tensorflow import keras\n",
        "\n",
        "model_v = keras.Model(inputs  = model.inputs, outputs = model.layers[0].output)\n",
        "model_v.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H_oRsZvhH8_",
        "outputId": "ebaf5588-b0e8-4da7-fbe0-f654cb38f8ef"
      },
      "outputs": [],
      "source": [
        "# Get the feature maps for an image\n",
        "im = train_images[14]\n",
        "feature_maps = model_v.predict(im.reshape(1,32,32,3))   # reshape method is necessary because\n",
        "                                                        # train_images[k] has the shape (32,32,3) while predict\n",
        "                                                        # wants a 4d input. Using reshape, we can create\n",
        "                                                        # a 4d array having just 1 element\n",
        "\n",
        "# Print the shape of feature_maps\n",
        "print(feature_maps.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "VAO9_5_yhJne",
        "outputId": "ef70994d-bdd1-49dd-b95c-31dd384610b3"
      },
      "outputs": [],
      "source": [
        "# Show the image for which we want to compute the feature maps and its class\n",
        "plt.imshow(im)\n",
        "p=(model(im.reshape(1,32,32,3)))\n",
        "print(class_names[np.argmax(p)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "I6k-GFfKhYh_",
        "outputId": "c0f012a8-990b-45f2-810f-9f1addda0300"
      },
      "outputs": [],
      "source": [
        "# Show the feature map corresponding to a given filter as an image\n",
        "# Remember that feature_maps.shape = (1, 30, 30, 32) where the 4th entry represents the filters\n",
        "fmap=feature_maps[0,:,:,5]\n",
        "print(fmap.shape)\n",
        "\n",
        "plt.imshow(fmap,cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RnT46XikhaCT",
        "outputId": "ac92c228-a46e-4011-c3f3-a9dd22ebe75b"
      },
      "outputs": [],
      "source": [
        "# Show all the feature maps\n",
        "import matplotlib as mpl\n",
        "fig  = plt.figure(figsize=(8,16))\n",
        "\n",
        "for i in range(32):\n",
        "    sub = fig.add_subplot(8,4, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    sub.imshow(feature_maps[0,:,:,i], cmap = \"gray\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Repeat the above process to show the feature maps extracted by the second conv layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynGP_HWHhd9Z",
        "outputId": "049fddea-4bb7-48b0-af29-7eaf9811904e"
      },
      "outputs": [],
      "source": [
        "# Build a new model to output right after the second conv layer (list index = 2)\n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlCeynljhfkm",
        "outputId": "45cac3be-cd72-4a47-8300-9dd430d3d2f3"
      },
      "outputs": [],
      "source": [
        "# Get the feature maps for the image\n",
        "feature_maps_2 = model_v_2.predict(im.reshape(1,32,32,3))\n",
        "print(feature_maps_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "LZfmi536hg0O",
        "outputId": "ec773819-cda0-45fc-ac30-2b1f51e507da"
      },
      "outputs": [],
      "source": [
        "# Plot all the feature maps\n",
        "fig  = plt.figure(figsize=(12,12))\n",
        "\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Repeat the above process to show the feature maps extracted by the third conv layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "VTiyhwoYhiEj",
        "outputId": "4629f9aa-3fb1-4e5b-997d-3a922fdee48c"
      },
      "outputs": [],
      "source": [
        "# Build a new model to output right after the third conv layer (list index = 4)\n",
        "model_v_4 = keras.Model(inputs = model.inputs, outputs = model.layers[4].output)\n",
        "\n",
        "\n",
        "# Get the feature maps for an image\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6yUpaylMULv"
      },
      "source": [
        "### Plot the learned Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYDQYwwmMULv"
      },
      "outputs": [],
      "source": [
        "# Extracting the weights of the first convolutional layer\n",
        "conv_weights = model.layers[0].get_weights()[0]\n",
        "\n",
        "# Normalizing the weights to [0, 1]\n",
        "conv_weights_normalized = (conv_weights - np.min(conv_weights)) / (np.max(conv_weights) - np.min(conv_weights))\n",
        "\n",
        "# Plotting the learned filters\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(conv_weights.shape[-1]):\n",
        "    plt.subplot(6, 6, i + 1)\n",
        "    plt.imshow(conv_weights_normalized[:, :, :, i].squeeze(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Filter {i+1}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJgvSzufhn1n"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model.save('model_cnn.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTtrIfiHMULv"
      },
      "source": [
        "### HOMEWORK:\n",
        "- get a better CNN model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
