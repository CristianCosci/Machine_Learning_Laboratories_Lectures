{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering with Machine Learning\n",
        "\n",
        "This notebook provides an introduction to clustering techniques in machine learning. \n",
        "We will explore **KMeans**, **DBSCAN**, and **Hierarchical Clustering** algorithms to partition datasets into homogeneous groups. \n",
        "\n",
        "Clustering is essential for various applications, from market segmentation to data analysis. Let's dive in!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jOXcTgO4zxZB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Unzip the Dataset if you need to do it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('dataset/dataset_clustering.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading and Exploration "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2-KeANY0Lx2"
      },
      "outputs": [],
      "source": [
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuxmCse00e3B"
      },
      "outputs": [],
      "source": [
        "# Data shape\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualize data using scatter plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85oT6Voo0waU"
      },
      "outputs": [],
      "source": [
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## *Clustering Techniques*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Kmeans**\n",
        "\n",
        "Look at [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Write a function to call KMeans constructor and fit method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "k57SQp2gBJ2X"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans \n",
        "\n",
        "def build_kmeans():\n",
        "  ?\n",
        "  return kmeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert in numpy array and delete one column in order to have 2-dimensional data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYITE_sH1_g4"
      },
      "outputs": [],
      "source": [
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create 4 clusters from data using the previously defined function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufht4tu_1sKH"
      },
      "outputs": [],
      "source": [
        "kmeans4 = build_kmeans(4, my_dummy_data)\n",
        "\n",
        "# Print the centers of the clusters\n",
        "kmeans4.cluster_centers_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaPMLTAH3i8C"
      },
      "outputs": [],
      "source": [
        "# Visualize the data with the final centroids\n",
        "\n",
        "plt.scatter(my_dummy_data[:, 0], my_dummy_data[:,1])\n",
        "plt.scatter(kmeans4.cluster_centers_[:,0], kmeans4.cluster_centers_[:,1], s= 250, marker=\"*\", \n",
        "            c=\"yellow\", edgecolors=\"black\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GBRMuXe94euV"
      },
      "outputs": [],
      "source": [
        "# Create 3 clusters from data using the previously defined function\n",
        "kmeans3 = build_kmeans(3, my_dummy_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdav8Wdc4zC3"
      },
      "outputs": [],
      "source": [
        "# Visualize the data with the final centroids for both the models\n",
        "plt.scatter(my_dummy_data[:, 0], my_dummy_data[:,1])\n",
        "plt.scatter(kmeans3.cluster_centers_[:,0], kmeans3.cluster_centers_[:,1], s= 250, marker=\"*\", \n",
        "            c=\"yellow\", edgecolors=\"black\", label='3 cluster')\n",
        "plt.scatter(kmeans4.cluster_centers_[:,0], kmeans4.cluster_centers_[:,1], s= 10, marker=\"o\", \n",
        "            c=\"red\", edgecolors=\"black\", label='4 cluster')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# calling labels_ attribute we can see the cluster label of each point\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Selecting the optimal number of clusters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Elbow Method for Determining the Optimal Number of Clusters in K-means\n",
        "\n",
        "The elbow method for determining the optimal number of clusters in K-means involves:\n",
        "\n",
        "1. Computing the Within-Cluster Sum of Squares (WCSS) for different values of k (the number of clusters).\n",
        "2. Plotting k against WCSS.\n",
        "3. Identifying the \"elbow\" point in the plot, where the rate of decrease of WCSS slows down significantly.\n",
        "4. Selecting the number of clusters corresponding to this elbow point as the optimal number of clusters for the dataset.\n",
        "\n",
        "- Note that: `kMeans.inertia` = WCSS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDnYuNWV52FM"
      },
      "outputs": [],
      "source": [
        "?\n",
        "error = [] # array to collect the measure values\n",
        "?\n",
        "\n",
        "plt.plot(range(1,number_of_cluster),error )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "error[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Selecting the number of clusters with silhouette analysis on KMeans clustering\n",
        "Silhouette analysis can be used to study the separation distance between the resulting clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of `[-1, 1]`.\n",
        "\n",
        "Silhouette coefficients (as these values are referred to as) near `+1` indicate that the sample is far away from the neighboring clusters. A value of `0` indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.\n",
        "\n",
        "Also from the thickness of the silhouette plot the cluster size can be visualized.\n",
        "\n",
        "[see here](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "X = my_dummy_data.copy()\n",
        "\n",
        "range_n_clusters = [2, 3, 4, 5, 6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Create a subplot with 1 row and 2 columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "    # lie within [-0.1, 1]\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Initialize the clusterer with n_clusters\n",
        "    clusterer = build_kmeans(n_clusters, X)\n",
        "    cluster_labels = clusterer.predict(X)\n",
        "\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\n",
        "        \"For n_clusters =\",\n",
        "        n_clusters,\n",
        "        \"The average silhouette_score is :\",\n",
        "        silhouette_avg,\n",
        "    )\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(\n",
        "            np.arange(y_lower, y_upper),\n",
        "            0,\n",
        "            ith_cluster_silhouette_values,\n",
        "            facecolor=color,\n",
        "            edgecolor=color,\n",
        "            alpha=0.7,\n",
        "        )\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # 2nd Plot showing the actual clusters formed\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "    ax2.scatter(\n",
        "        X[:, 0], X[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
        "    )\n",
        "\n",
        "    # Labeling the clusters\n",
        "    centers = clusterer.cluster_centers_\n",
        "    # Draw white circles at cluster centers\n",
        "    ax2.scatter(\n",
        "        centers[:, 0],\n",
        "        centers[:, 1],\n",
        "        marker=\"o\",\n",
        "        c=\"white\",\n",
        "        alpha=1,\n",
        "        s=200,\n",
        "        edgecolor=\"k\",\n",
        "    )\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "    plt.suptitle(\n",
        "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\"\n",
        "        % n_clusters,\n",
        "        fontsize=14,\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `Random` vs `k-means++` initialization\n",
        "\n",
        "- `k-means++` : selects initial cluster centroids using sampling based on an empirical probability distribution of the points’ contribution to the overall inertia. This technique **speeds up convergence**. The algorithm implemented is “greedy k-means++”. It differs from the vanilla k-means++ by making several trials at each sampling step and choosing the best centroid among them.\n",
        "- `random`: choose n_clusters observations (rows) at random from data for the initial centroids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WpSyxr4AaVQ"
      },
      "outputs": [],
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10,6))\n",
        "ax1.set_title(\"k means++ 4\")\n",
        "ax2.set_title(\"k means++ 3\")\n",
        "\n",
        "ax1.scatter(my_dummy_data[:,0], my_dummy_data[:,1], c = kmeans4.labels_, cmap =\"brg\" )\n",
        "ax1.scatter(kmeans4.cluster_centers_[:,0], kmeans4.cluster_centers_[:,1], s = 250, marker = \"*\", c=\"yellow\", edgecolors=\"black\")\n",
        "\n",
        "ax2.scatter(my_dummy_data[:,0], my_dummy_data[:,1], c = kmeans3.labels_, cmap =\"brg\" )\n",
        "ax2.scatter(kmeans3.cluster_centers_[:,0], kmeans3.cluster_centers_[:,1], s = 80, marker = \"o\", c=\"yellow\", edgecolors=\"black\")\n",
        "\n",
        "##################################################################################\n",
        "\n",
        "kmeans4_rand = build_kmeans(4, my_dummy_data, \"random\", 1, 2)\n",
        "kmeans3_rand = build_kmeans(3, my_dummy_data, \"random\", 1, 2)\n",
        "\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10,6))\n",
        "ax1.set_title(\"k means 4 random_init\")\n",
        "ax2.set_title(\"k means 3 random_init\")\n",
        "\n",
        "ax1.scatter(my_dummy_data[:,0], my_dummy_data[:,1], c = kmeans4_rand.labels_, cmap =\"brg\" )\n",
        "ax1.scatter(kmeans4_rand.cluster_centers_[:,0], kmeans4_rand.cluster_centers_[:,1], s = 250, marker = \"*\", c=\"yellow\", edgecolors=\"black\")\n",
        "\n",
        "ax2.scatter(my_dummy_data[:,0], my_dummy_data[:,1], c = kmeans3_rand.labels_, cmap =\"brg\" )\n",
        "ax2.scatter(kmeans3_rand.cluster_centers_[:,0], kmeans3_rand.cluster_centers_[:,1], s = 80, marker = \"o\", c=\"yellow\", edgecolors=\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Re-run the code with `3D data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "?\n",
        "error = [] # array to collect the measure values\n",
        "\n",
        "\n",
        "plt.plot(range(1,number_of_cluster),error )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans4 = build_kmeans(4, my_dummy_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (10,10))\n",
        "ax = plt.axes(projection='3d')\n",
        "ax.grid()\n",
        "\n",
        "ax.scatter(my_dummy_data[:, 0], my_dummy_data[:, 1], my_dummy_data[:, 2], c = 'b', s = 1)\n",
        "ax.scatter(kmeans4.cluster_centers_[:,0], kmeans4.cluster_centers_[:,1], kmeans4.cluster_centers_[:,2], s= 10000, marker=\"*\", \n",
        "            c=\"yellow\", edgecolors=\"black\")\n",
        "ax.set_title('3D Scatter Plot')\n",
        "\n",
        "# Set axes label\n",
        "ax.set_xlabel('x', labelpad=20)\n",
        "ax.set_ylabel('y', labelpad=20)\n",
        "ax.set_zlabel('z', labelpad=20)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **DBSCAN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To find the best parameters **Eps** and **MinPts** for DBSCAN we can use the elbow method by plotting the distance of the `k_th` neighbors. \n",
        "\n",
        "To do this we can use the methods provided by the class [`NearestNeighbors`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors).\n",
        "\n",
        "In particular we can use the kneighbors method (applied on the trained model) to find the **K-neighbors** of a point.\n",
        "\n",
        "Look at DBSCAN [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "my_dummy_data = dummy_dataset.to_numpy()\n",
        "print(my_dummy_data[:5],'\\n')\n",
        "\n",
        "my_dummy_data = np.delete(my_dummy_data, 0, axis=1)\n",
        "print(my_dummy_data[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFXEh5rU8Eds"
      },
      "outputs": [],
      "source": [
        "neighbors = NearestNeighbors(n_neighbors=8) # set n_neighbors to the MinPts you want to analyze (try 8 for good results)\n",
        "neighbors_fit = neighbors.fit(my_dummy_data)\n",
        "distances, indices = neighbors_fit.kneighbors(my_dummy_data)\n",
        "\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:,1]\n",
        "plt.plot(distances)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "bO-vhAXiDSnT"
      },
      "outputs": [],
      "source": [
        "# Call DBSCAN and fit a model on the same dataset\n",
        "\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analyze the assigned labels in order to retrieve the number of clusters and noise points\n",
        "- `-1` is the label assigned to noise points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels=dbscan.labels_\n",
        "print(\"type(labels)=\",type(labels))\n",
        "print(labels)\n",
        "\n",
        "nl=np.unique(labels)\n",
        "print(\"Assigned labels: \",nl)\n",
        "\n",
        "n_clusters = len(np.unique(labels)) - (1 if -1 in labels else 0)\n",
        "\n",
        "n_noise = list(labels).count(-1)\n",
        "\n",
        "print(\"Estimated number of clusters:\", n_clusters)\n",
        "print(\"Estimated number of noise points:\",n_noise, \"representing \",n_noise*100/dummy_dataset.shape[0],\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1J7NPSAD_A6"
      },
      "outputs": [],
      "source": [
        "# Visualize clusters using different colors for different labels\n",
        "plt.scatter(my_dummy_data[:, 0], my_dummy_data[:,1], c = dbscan.labels_, cmap =\"brg\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwxiuxoy97lS"
      },
      "outputs": [],
      "source": [
        "# Read dummy_dataset.csv file and visualize the first records\n",
        "dummy_dataset_bis = pd.read_csv(\"dataset/dummy_dataset.csv\", sep = ';')\n",
        "print(dummy_dataset_bis.head())\n",
        "print(dummy_dataset_bis.shape)\n",
        "\n",
        "my_dummy_data_bis = dummy_dataset_bis.to_numpy()\n",
        "print(my_dummy_data_bis[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSc3fgvk_HQa"
      },
      "outputs": [],
      "source": [
        "#  Visualize the data (2D scatter plot)\n",
        "plt.scatter(my_dummy_data_bis[:,0],my_dummy_data_bis[:,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "pB44VRLT_e7h"
      },
      "outputs": [],
      "source": [
        "# Apply kmeans with k=5 \n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8tSi3IO_1mG"
      },
      "outputs": [],
      "source": [
        "# Visualize centers and colored clusters\n",
        "plt.scatter(my_dummy_data_bis[:,0],my_dummy_data_bis[:,1], c = kmeans_bis.labels_)\n",
        "plt.scatter(kmeans_bis.cluster_centers_[:,0], kmeans_bis.cluster_centers_[:,1], marker = \"*\", c = \"yellow\", s=150, edgecolors=\"black\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6zaJUIw-Lsa"
      },
      "outputs": [],
      "source": [
        "# Use the elbow method defined above to plot, for each point, the k-th neighbor distance \n",
        "# n_neighbors=3 is a good value for this dataset\n",
        "\n",
        "neighbors = NearestNeighbors(n_neighbors=3)\n",
        "neighbors_fit = neighbors.fit(my_dummy_data_bis)\n",
        "distances, indices = neighbors_fit.kneighbors(my_dummy_data_bis)\n",
        "\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:,1]\n",
        "plt.plot(distances)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "t76WthXSBHqr"
      },
      "outputs": [],
      "source": [
        "# APPLY DB SCAN (eps=0.4 works well) \n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TykTuWOEBfOv"
      },
      "outputs": [],
      "source": [
        "# visualize the colored clusters\n",
        "plt.scatter(my_dummy_data_bis[:,0],my_dummy_data_bis[:,1], c = dbscan_bis.labels_, cmap = \"plasma\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Agglomerative Clustering**\n",
        "\n",
        "Look ad Agglomerative CLustering [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbE90MjFvfoo"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To visualize the dendogram we can use the scipy library in this case also the clustering is made by the methods in scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h9yr8ME2KC3"
      },
      "outputs": [],
      "source": [
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "out_linkage=sch.linkage(my_dummy_data, method = \"average\")\n",
        "d = sch.dendrogram (out_linkage)\n",
        "plt.title(\"dendrogram\")\n",
        "plt.xlabel(\"Clusters\")\n",
        "plt.ylabel(\"Euclidean\")\n",
        "plt.axhline(y = 4.5, color = \"r\", linestyle = \"-\")\n",
        "plt.axhline(y = 3.5, color = \"black\", linestyle = \"-\")\n",
        "plt.axhline(y = 2.5, color = \"yellow\", linestyle = \"-\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKS4dmhswCVp"
      },
      "outputs": [],
      "source": [
        "?\n",
        "\n",
        "plt.scatter(my_dummy_data_bis[:,0],my_dummy_data_bis[:,1], c = y_agglo_bis,cmap = \"plasma\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
