{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRhnLjGg5zVH"
      },
      "source": [
        "# Anomaly Detection using CNN Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpdVh65W6ibR"
      },
      "source": [
        "### Loading Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UStyj-35-_jN",
        "outputId": "753bc2d1-605f-4294-dfb0-73f8cb6e1ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUt_5pgQ_fXr"
      },
      "outputs": [],
      "source": [
        "!unzip -qo \"/content/drive/MyDrive/Colab Notebooks/Corso_ML/fruits_anomaly_detection.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaHyHQpq42B"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMCQsCrn6eeN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import array_to_img, img_to_array, load_img\n",
        "from PIL import Image, ImageChops\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC-Hh-ZfEfrC"
      },
      "source": [
        "### Create generators for training, validation and testing\n",
        "\n",
        "- Read data from folders using ImageDataGenerator\n",
        "- Generate data from the images in a folder, allows use of datasets that do not fit in main memory all at once\n",
        "- Image resizing is done by the generator so a folder with any sized-images can be used\n",
        "\n",
        "The named directory must contain one or more subfolders, path should look like `apples_train/apple_class1/img1.jpg`\n",
        "\n",
        "\n",
        "- Generate batches of tensor image data with real-time data augmentation.\n",
        "- A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels.\n",
        "\n",
        "---\n",
        "`flow_from_directory(directory)`\n",
        "\n",
        "**Description**: Takes the path to a directory, and generates batches of augmented/normalized data (Yields batches indefinitely, in an infinite loop.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwzPluRfqK-O",
        "outputId": "810debf6-254a-4d3f-fa81-cb8c3282d65b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6416 images belonging to 13 classes.\n",
            "Found 2138 images belonging to 13 classes.\n",
            "Found 468 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 85\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last') # 96x96x3\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/fruits_anomaly_detection/apples_train',\n",
        "    target_size=(96, 96),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'   # the output is the input itself\n",
        "    )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/fruits_anomaly_detection/apples_test/',\n",
        "    target_size=(96, 96),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'\n",
        "    )\n",
        "\n",
        "anomaly_generator = test_datagen.flow_from_directory(\n",
        "    '/content/fruits_anomaly_detection/eggplant',\n",
        "    target_size=(96, 96),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='input'\n",
        "    )\n",
        "#(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap73VRaKq98w"
      },
      "source": [
        "## **Autoencoder Architecture**\n",
        "\n",
        "As we have seen in the case of MLP Autoencoder, we build a structure composed by an **Encoder**, that able to reduce the dimensions of our data (extract latent fetaures), and a **Decoder**, that is able to restore the original dimensions.\n",
        "\n",
        "The output has to have the same structure of the input, the objective is to learn a model able to reconstruct well (producing small reconstruction error) data coming from the same distribution of the training data.\n",
        "\n",
        "Different data (for example anomalies) should produce higher reconstruction error.\n",
        "\n",
        "In order to inncrease the data size in the Decoder part we can use the class\n",
        "**`UpSampling2D`**  https://keras.io/api/layers/reshaping_layers/up_sampling2d/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv6VPQTirAbu"
      },
      "outputs": [],
      "source": [
        "# Define the convolutional autoencoder model\n",
        "\n",
        "# input shape must be the same size as the images that will be fed into it by the generators\n",
        "# The output layer must be the same dimensions as the original image\n",
        "model = Sequential()\n",
        "#-------------------------\n",
        "\n",
        "?\n",
        "?\n",
        "?\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='')\n",
        "# ... can compute the difference between the image in input and the one produced in output (the reconstructed one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teWhDR51ruJd"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXnUE6l3FyOx"
      },
      "source": [
        "Define `steps_per_epoch`:\n",
        "- Is the Total number of steps (batches of samples) to yield from generator\n",
        "- before declaring one epoch finished and starting the next epoch.\n",
        "- It should typically be equal to `ceil(num_samples / batch_size)`.\n",
        "\n",
        "EarlyStopping callback in combination with ModelCheckpoint https://keras.io/api/callbacks/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-N87K0Nrv-s",
        "outputId": "fc0af51d-89dd-4c61-b26b-687cc546c2fa"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "?\n",
        "\n",
        "# Early stopping (stops training when validation doesn't improve for {patience} epochs)\n",
        "?\n",
        "# Saves the best version of the model to disk (as measured on the validation data set)\n",
        "\n",
        "# model.fit(X_train, y_train, etc..)\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZfYmKqTGJye"
      },
      "source": [
        "Training continues after improvement stops for the number of epochs equivalent to the 'patience' hyper-parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0-WehjjvKrb",
        "outputId": "ab3a0f6d-b65e-45b8-c4f7-6fbf75f5b3e0"
      },
      "outputs": [],
      "source": [
        "# To get back the model that performed best on the validation set we load the checkpointed model from disk:\n",
        "model_filepath = 'image_anomaly_ae.h5'\n",
        "model = keras.models.load_model(model_filepath)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtoN_ZPqGPa8"
      },
      "source": [
        "Test the model by viewing a sample of original and reconstructed images.\n",
        "\n",
        "A `DirectoryIterator` yielding tuples of `(x, y)` where `x` is a numpy array containing a batch of images with shape `(batch_size, *target_size, channels)` and `y` is a numpy array of corresponding labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "griOa5DBHLki"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uQXjTBQvmcR",
        "outputId": "05bab55f-bfc9-475c-af32-b7fbde21d0d4"
      },
      "outputs": [],
      "source": [
        "# Get extract some batches with the generator\n",
        "data_list = []\n",
        "batch_index = 0\n",
        "while batch_index <= train_generator.batch_index:\n",
        "    data = train_generator.next()\n",
        "    data_list.append(data[0]) # just get the input batches\n",
        "    ## each entry is a batch of shape (n_records,size,size,channels)=(85,96,96,3)\n",
        "    batch_index = batch_index + 1\n",
        "\n",
        "print(len(data_list))\n",
        "print(data_list[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "xb0OR2FjU8AB",
        "outputId": "97a28ab4-cc41-46f5-f459-ebdecd276ac0"
      },
      "outputs": [],
      "source": [
        "# Plot some original samples vs reconstructed samples\n",
        "\n",
        "predicted = model.predict(data_list[0])   #compute prediction for the first batch\n",
        "\n",
        "no_of_samples = 4\n",
        "_, axs = plt.subplots(no_of_samples, 2, figsize=(5, 8))\n",
        "axs = axs.flatten()\n",
        "imgs = []\n",
        "for i in range(no_of_samples):\n",
        "    imgs.append(data_list[0][i])\n",
        "    imgs.append(predicted[i])\n",
        "\n",
        "for img, ax in zip(imgs, axs):\n",
        "    ax.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efuhC1X635OZ",
        "outputId": "df5df996-791c-47d5-f024-0381690e6350"
      },
      "outputs": [],
      "source": [
        "# Get images from eggplant (which we consider to be anomalous data)\n",
        "\n",
        "# Test the model by viewing a sample of original and reconstructed images\n",
        "eggplant_data_list = []\n",
        "batch_index = 0\n",
        "while batch_index <= anomaly_generator.batch_index:\n",
        "    print(\"batch_index: \", batch_index, \"anomaly_generator batch_index: \", anomaly_generator.batch_index)\n",
        "    data = anomaly_generator.next()\n",
        "    eggplant_data_list.append(data[0])\n",
        "    batch_index = batch_index + 1\n",
        "\n",
        "print(len(eggplant_data_list))\n",
        "print(eggplant_data_list[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "KGFGaYlIYjIn",
        "outputId": "4c21689b-ffd5-427a-e395-981f7abd4b1f"
      },
      "outputs": [],
      "source": [
        "# Plot some original eggplants vs reconstructed eggplants\n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IERMGevMWXoF",
        "outputId": "6f1bb8fa-9d43-4463-c400-3889c74409d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "26\n",
            "(85, 96, 96, 3)\n"
          ]
        }
      ],
      "source": [
        "# Get images from apple test\n",
        "\n",
        "# Test the model by viewing a sample of original and reconstructed images\n",
        "apple_test_list = []\n",
        "batch_index = 0\n",
        "while batch_index <= validation_generator.batch_index:\n",
        "    #print(\"batch_index: \", batch_index, \"validation_generator batch_index: \", validation_generator.batch_index)\n",
        "    data = validation_generator.next()\n",
        "    apple_test_list.append(data[0]) #just get the input batches\n",
        "    batch_index = batch_index + 1\n",
        "\n",
        "print(len(apple_test_list))\n",
        "print(apple_test_list[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "-n7lo_h3E8eT",
        "outputId": "4b6ac0d7-86ac-43d1-dd91-e252d2557a00"
      },
      "outputs": [],
      "source": [
        "# Apple test samples: original vs reconstructed\n",
        "?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs6up9dKHHKA"
      },
      "source": [
        "### **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQRPEVOsvs-X",
        "outputId": "4efdfcd8-53d3-4cd2-da6b-7e3671985059"
      },
      "outputs": [],
      "source": [
        "# We want the difference the difference in error between the validation (normal) images and anomalous images to be as high as possible\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0IS2_g2FFFn"
      },
      "source": [
        "#### **Analysis of the reconstruction errors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "id": "YKcCdTUwWqJ3",
        "outputId": "2416c8c8-b2f7-4849-9381-92a4ac927f4f"
      },
      "outputs": [],
      "source": [
        "error_list = []\n",
        "for idx in range(len(apple_test_list)): #iterate over batches\n",
        "\n",
        "  r = model.predict(apple_test_list[idx])   #get prediction of batch with index idx\n",
        "\n",
        "  #MSE\n",
        "  r_error  = [np.square(apple_test_list[idx][i] - r[i]).mean() for i in range(len(apple_test_list[idx]))]\n",
        "  # MSE Mean squared (reconstruction) error between the original image and the reconstructed one\n",
        "  error_list.append(r_error) #error_list is a list of list: so I will flatten everything out.\n",
        "\n",
        "\n",
        "error_flat_list = [item for sublist in error_list for item in sublist]\n",
        "\n",
        "plt.scatter(x = range(len(error_flat_list)), y = sorted(error_flat_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "id": "Cdpq6nIQrRQE",
        "outputId": "fa01b470-490c-4964-c10e-dce2bf1b3e6e"
      },
      "outputs": [],
      "source": [
        "# Get the reconstructions errors for eggplants\n",
        "error_list_eggplant = []\n",
        "for idx in range(len(eggplant_data_list)):\n",
        "  r = model.predict(eggplant_data_list[idx])\n",
        "\n",
        "  r_error  = [np.square(eggplant_data_list[idx][i] - r[i]).mean() for i in range(len(eggplant_data_list[idx]))]\n",
        "\n",
        "  error_list_eggplant.append(r_error)\n",
        "\n",
        "error_flat_list_eggplant = [item for sublist in error_list_eggplant for item in sublist]\n",
        "# total_error = sum(error_flat_list_eggplant)\n",
        "\n",
        "plt.scatter(x = range(len(error_flat_list_eggplant)), y = sorted(error_flat_list_eggplant))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj2Bpd2AJc94"
      },
      "source": [
        "#### **Count anomalies on apple test given a threshold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH0Rym-IZ-qa",
        "outputId": "ea559e9e-645a-4480-c4f7-09b3f7424c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apple test anomaly 20 over a total of 2138 apple test\n",
            "0.009354536950420954\n"
          ]
        }
      ],
      "source": [
        "# Anomaly detection on apple_test samples\n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt9U-_4bKofT",
        "outputId": "a875a5db-652b-4cfc-dee0-6ce52f2deba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eggplant anomaly 438 over a total of 468 eggplant test\n",
            "0.9358974358974359\n"
          ]
        }
      ],
      "source": [
        "# Count anomalies on eggplants\n",
        "#anomaly detection in the eggplant samples\n",
        "?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXUNdB1fJfzR"
      },
      "source": [
        "#### **ROC Curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLJMup4wKmLe",
        "outputId": "4ad9ab15-1c2e-4320-e2cb-c4932b8ebb7a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
        "                             roc_curve, recall_score, classification_report, f1_score,\n",
        "                             precision_recall_fscore_support)\n",
        "import pandas as pd\n",
        "\n",
        "# Assign labels\n",
        "# Create labels for normal and anomaly samples\n",
        "apple_test_labels =  np.zeros(len(error_flat_list))    #normal label = 0\n",
        "eggplant_test_labels = np.ones(len(error_flat_list_eggplant)) #anomaly label = 1\n",
        "\n",
        "# Put all the labels together\n",
        "all_labels = np.concatenate((apple_test_labels, eggplant_test_labels))\n",
        "\n",
        "# Put together the reconstruction errors and Target_scores\n",
        "all_errors  = error_flat_list + error_flat_list_eggplant\n",
        "\n",
        "# Create a dataframe to store all the above information, to have everything together\n",
        "# This way we can compute some statistics easily\n",
        "\n",
        "error_df = pd.DataFrame({'reconstruction_error': all_errors,\n",
        "                         \"true_class\": all_labels})\n",
        "error_df.describe()\n",
        "print(error_df.head())\n",
        "print(error_df.tail())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "L9QWAdnsMzNb",
        "outputId": "593c88ea-aa55-45a9-89d6-c92cb9002718"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)\n",
        "# fpr, tpr, thresholds = roc_curve(all_labels, all_errors)\n",
        "\n",
        "# AUC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "\n",
        "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0UTxf5RUg5L",
        "outputId": "430a6ec9-3009-4e26-cd7b-cfb588920d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold ottimale: 0.02499602\n"
          ]
        }
      ],
      "source": [
        "optimal_idx = np.argmax(tpr - fpr)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "print(\"Threshold ottimale:\", optimal_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lya86OikXVjn"
      },
      "source": [
        "## **OneClass SVM for anomaly detection**\n",
        "\n",
        " SVMs use hyperplanes in multi-dimensional space to separate one class of observations from another. Naturally, SVM is used in solving multi-class classification problems.\n",
        "\n",
        "However, SVM is also increasingly being used in one class problem, where all data belong to a single class. In this case, the algorithm is trained to learn what is “normal”, so that when a new data is shown the algorithm can identify whether it should belong to the group or not. If not, the new data is labeled as out of ordinary or anomaly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYG_zSHIKmZW"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.datasets import make_blobs\n",
        "from numpy import quantile, where, random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFwKoM_BXeQI"
      },
      "source": [
        "**Preparing the data**\n",
        "\n",
        "We create a toy dataset for this tutorial by using the make_blob() function. We can check the dataset by visualizing it in a plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "va4FKZy2Xqs-",
        "outputId": "586f3517-2b8b-43f0-8879-13f56419d273"
      },
      "outputs": [],
      "source": [
        "random.seed(13)\n",
        "x, _ = make_blobs(n_samples=200, centers=1, cluster_std=.3, center_box=(8, 8))\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HbFoIpqXtxy"
      },
      "source": [
        "**Defining the model and prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "hmk5nOkJXz1g",
        "outputId": "107d23eb-a862-471d-dfa2-ae3c07912acb"
      },
      "outputs": [],
      "source": [
        "# Create the model\n",
        "?\n",
        "\n",
        "# Fit the model & predict\n",
        "?\n",
        "\n",
        "# Extract the negative outputs as outliers\n",
        "?\n",
        "\n",
        "#visualize the results in a plot, highlighting with red the anomalies/outliers\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0], values[:,1], color='r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jPOaV0uVZCSX",
        "outputId": "69b972c1-7fca-4952-b008-a2b2c6e6543c"
      },
      "outputs": [],
      "source": [
        "# anomaly detection with scores\n",
        "# We can find anomalies by using their scores.\n",
        "# In this method, we'll define the model, fit it on the x data by using the fit_predict() method.\n",
        "# We'll calculate the outliers according to the score value of each element.\n",
        "\n",
        "?\n",
        "\n",
        "print(scores)\n",
        "\n",
        "# Get the threshold values from the scores using the quantile function\n",
        "#for example, get the lowest 3-percent of score values as the anomalies\n",
        "?\n",
        "\n",
        "# Extract the anomalies by comparing the threshold value and identify the values of elements\n",
        "?\n",
        "\n",
        "#visualize the data, anomalies are colored in red\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.scatter(values[:,0], values[:,1], color='r')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
